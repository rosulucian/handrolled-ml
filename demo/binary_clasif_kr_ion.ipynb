{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/ionosphere.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv(path, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.95217</td>\n",
       "      <td>0.06595</td>\n",
       "      <td>0.93614</td>\n",
       "      <td>0.13030</td>\n",
       "      <td>0.90996</td>\n",
       "      <td>0.19152</td>\n",
       "      <td>0.84881</td>\n",
       "      <td>-0.49962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.44199</td>\n",
       "      <td>0.34374</td>\n",
       "      <td>0.43221</td>\n",
       "      <td>0.90330</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.23405</td>\n",
       "      <td>0.39620</td>\n",
       "      <td>0.18632</td>\n",
       "      <td>0.37191</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.89706</td>\n",
       "      <td>0.38235</td>\n",
       "      <td>0.91176</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>0.74265</td>\n",
       "      <td>0.67647</td>\n",
       "      <td>0.45588</td>\n",
       "      <td>0.77941</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.12500</td>\n",
       "      <td>-0.67925</td>\n",
       "      <td>-0.24131</td>\n",
       "      <td>-0.55147</td>\n",
       "      <td>-0.42647</td>\n",
       "      <td>-0.44118</td>\n",
       "      <td>-0.50735</td>\n",
       "      <td>-0.28676</td>\n",
       "      <td>-0.56618</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03852</td>\n",
       "      <td>0.02568</td>\n",
       "      <td>0.00428</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.01997</td>\n",
       "      <td>-0.01997</td>\n",
       "      <td>0.02140</td>\n",
       "      <td>-0.04993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01854</td>\n",
       "      <td>0.03994</td>\n",
       "      <td>0.01569</td>\n",
       "      <td>0.01997</td>\n",
       "      <td>0.00713</td>\n",
       "      <td>-0.02568</td>\n",
       "      <td>-0.01854</td>\n",
       "      <td>-0.01427</td>\n",
       "      <td>0.01997</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01667</td>\n",
       "      <td>-0.35625</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.16667</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.76667</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.18854</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.27292</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.14236</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.16256</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.23656</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.07514</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.47643</td>\n",
       "      <td>0.98820</td>\n",
       "      <td>-0.49687</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.75820</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.75761</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.84437</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1        2        3        4        5        6        7        8   \\\n",
       "125   1   0  0.95217  0.06595  0.93614  0.13030  0.90996  0.19152  0.84881   \n",
       "135   1   0  0.89706  0.38235  0.91176  0.37500  0.74265  0.67647  0.45588   \n",
       "156   1   0  0.03852  0.02568  0.00428  0.00000  0.01997 -0.01997  0.02140   \n",
       "61    1   0  0.01667 -0.35625  0.00000  0.00000  0.00000  0.00000  0.00000   \n",
       "30    1   0  1.00000 -0.14236  1.00000 -0.16256  1.00000 -0.23656  1.00000   \n",
       "\n",
       "          9   ...       25       26       27       28       29       30  \\\n",
       "125 -0.49962  ...  0.44199  0.34374  0.43221  0.90330  1.00000  0.23405   \n",
       "135  0.77941  ... -0.12500 -0.67925 -0.24131 -0.55147 -0.42647 -0.44118   \n",
       "156 -0.04993  ...  0.01854  0.03994  0.01569  0.01997  0.00713 -0.02568   \n",
       "61   0.00000  ... -0.16667  1.00000 -0.76667 -1.00000  0.18854  0.00000   \n",
       "30  -0.07514  ... -0.47643  0.98820 -0.49687  1.00000 -0.75820  1.00000   \n",
       "\n",
       "          31       32       33  34  \n",
       "125  0.39620  0.18632  0.37191   g  \n",
       "135 -0.50735 -0.28676 -0.56618   g  \n",
       "156 -0.01854 -0.01427  0.01997   b  \n",
       "61   0.00000  1.00000 -0.27292   b  \n",
       "30  -0.75761  1.00000 -0.84437   g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(351, 35)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.values[:,:-1]\n",
    "y = df.values[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = LabelEncoder().fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(235, 34) (116, 34) (235,) (116,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(8, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(3, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 235 samples\n",
      "Epoch 1/150\n",
      "235/235 [==============================] - 0s 2ms/sample - loss: 0.6731 - accuracy: 0.6340\n",
      "Epoch 2/150\n",
      "235/235 [==============================] - 0s 289us/sample - loss: 0.6451 - accuracy: 0.6340\n",
      "Epoch 3/150\n",
      "235/235 [==============================] - 0s 264us/sample - loss: 0.6264 - accuracy: 0.6340\n",
      "Epoch 4/150\n",
      "235/235 [==============================] - 0s 268us/sample - loss: 0.6075 - accuracy: 0.6340\n",
      "Epoch 5/150\n",
      "235/235 [==============================] - 0s 238us/sample - loss: 0.5911 - accuracy: 0.6340\n",
      "Epoch 6/150\n",
      "235/235 [==============================] - 0s 277us/sample - loss: 0.5755 - accuracy: 0.6426\n",
      "Epoch 7/150\n",
      "235/235 [==============================] - 0s 277us/sample - loss: 0.5591 - accuracy: 0.6511\n",
      "Epoch 8/150\n",
      "235/235 [==============================] - 0s 251us/sample - loss: 0.5452 - accuracy: 0.6596\n",
      "Epoch 9/150\n",
      "235/235 [==============================] - 0s 259us/sample - loss: 0.5281 - accuracy: 0.6809\n",
      "Epoch 10/150\n",
      "235/235 [==============================] - 0s 260us/sample - loss: 0.5119 - accuracy: 0.7149\n",
      "Epoch 11/150\n",
      "235/235 [==============================] - 0s 277us/sample - loss: 0.4960 - accuracy: 0.7319\n",
      "Epoch 12/150\n",
      "235/235 [==============================] - 0s 277us/sample - loss: 0.4808 - accuracy: 0.7660\n",
      "Epoch 13/150\n",
      "235/235 [==============================] - 0s 242us/sample - loss: 0.4648 - accuracy: 0.7745\n",
      "Epoch 14/150\n",
      "235/235 [==============================] - 0s 234us/sample - loss: 0.4500 - accuracy: 0.8213\n",
      "Epoch 15/150\n",
      "235/235 [==============================] - 0s 251us/sample - loss: 0.4348 - accuracy: 0.8340\n",
      "Epoch 16/150\n",
      "235/235 [==============================] - 0s 255us/sample - loss: 0.4189 - accuracy: 0.8553\n",
      "Epoch 17/150\n",
      "235/235 [==============================] - 0s 260us/sample - loss: 0.4043 - accuracy: 0.8553\n",
      "Epoch 18/150\n",
      "235/235 [==============================] - 0s 268us/sample - loss: 0.3910 - accuracy: 0.8638\n",
      "Epoch 19/150\n",
      "235/235 [==============================] - 0s 251us/sample - loss: 0.3776 - accuracy: 0.8723\n",
      "Epoch 20/150\n",
      "235/235 [==============================] - 0s 264us/sample - loss: 0.3667 - accuracy: 0.8851\n",
      "Epoch 21/150\n",
      "235/235 [==============================] - 0s 264us/sample - loss: 0.3540 - accuracy: 0.8851\n",
      "Epoch 22/150\n",
      "235/235 [==============================] - 0s 264us/sample - loss: 0.3468 - accuracy: 0.8851\n",
      "Epoch 23/150\n",
      "235/235 [==============================] - 0s 243us/sample - loss: 0.3351 - accuracy: 0.8894\n",
      "Epoch 24/150\n",
      "235/235 [==============================] - 0s 242us/sample - loss: 0.3217 - accuracy: 0.8894\n",
      "Epoch 25/150\n",
      "235/235 [==============================] - 0s 230us/sample - loss: 0.3116 - accuracy: 0.8936\n",
      "Epoch 26/150\n",
      "235/235 [==============================] - 0s 264us/sample - loss: 0.3017 - accuracy: 0.8979\n",
      "Epoch 27/150\n",
      "235/235 [==============================] - 0s 264us/sample - loss: 0.2919 - accuracy: 0.9064\n",
      "Epoch 28/150\n",
      "235/235 [==============================] - 0s 260us/sample - loss: 0.2840 - accuracy: 0.9064\n",
      "Epoch 29/150\n",
      "235/235 [==============================] - ETA: 0s - loss: 0.2719 - accuracy: 0.91 - 0s 268us/sample - loss: 0.2738 - accuracy: 0.9064\n",
      "Epoch 30/150\n",
      "235/235 [==============================] - 0s 243us/sample - loss: 0.2653 - accuracy: 0.9149\n",
      "Epoch 31/150\n",
      "235/235 [==============================] - 0s 238us/sample - loss: 0.2585 - accuracy: 0.9191\n",
      "Epoch 32/150\n",
      "235/235 [==============================] - 0s 243us/sample - loss: 0.2505 - accuracy: 0.9149\n",
      "Epoch 33/150\n",
      "235/235 [==============================] - 0s 251us/sample - loss: 0.2433 - accuracy: 0.9191\n",
      "Epoch 34/150\n",
      "235/235 [==============================] - 0s 260us/sample - loss: 0.2370 - accuracy: 0.9234\n",
      "Epoch 35/150\n",
      "235/235 [==============================] - 0s 245us/sample - loss: 0.2294 - accuracy: 0.9234\n",
      "Epoch 36/150\n",
      "235/235 [==============================] - 0s 260us/sample - loss: 0.2225 - accuracy: 0.9234\n",
      "Epoch 37/150\n",
      "235/235 [==============================] - 0s 255us/sample - loss: 0.2165 - accuracy: 0.9319\n",
      "Epoch 38/150\n",
      "235/235 [==============================] - 0s 277us/sample - loss: 0.2111 - accuracy: 0.9362\n",
      "Epoch 39/150\n",
      "235/235 [==============================] - 0s 289us/sample - loss: 0.2029 - accuracy: 0.9362\n",
      "Epoch 40/150\n",
      "235/235 [==============================] - 0s 264us/sample - loss: 0.1985 - accuracy: 0.9362\n",
      "Epoch 41/150\n",
      "235/235 [==============================] - 0s 281us/sample - loss: 0.1917 - accuracy: 0.9447\n",
      "Epoch 42/150\n",
      "235/235 [==============================] - 0s 251us/sample - loss: 0.1859 - accuracy: 0.9447\n",
      "Epoch 43/150\n",
      "235/235 [==============================] - 0s 243us/sample - loss: 0.1808 - accuracy: 0.9447\n",
      "Epoch 44/150\n",
      "235/235 [==============================] - 0s 294us/sample - loss: 0.1754 - accuracy: 0.9447\n",
      "Epoch 45/150\n",
      "235/235 [==============================] - 0s 294us/sample - loss: 0.1685 - accuracy: 0.9489\n",
      "Epoch 46/150\n",
      "235/235 [==============================] - 0s 285us/sample - loss: 0.1646 - accuracy: 0.9532\n",
      "Epoch 47/150\n",
      "235/235 [==============================] - 0s 247us/sample - loss: 0.1580 - accuracy: 0.9532\n",
      "Epoch 48/150\n",
      "235/235 [==============================] - 0s 268us/sample - loss: 0.1524 - accuracy: 0.9532\n",
      "Epoch 49/150\n",
      "235/235 [==============================] - 0s 260us/sample - loss: 0.1485 - accuracy: 0.9532\n",
      "Epoch 50/150\n",
      "235/235 [==============================] - 0s 274us/sample - loss: 0.1429 - accuracy: 0.9532\n",
      "Epoch 51/150\n",
      "235/235 [==============================] - 0s 260us/sample - loss: 0.1360 - accuracy: 0.9574\n",
      "Epoch 52/150\n",
      "235/235 [==============================] - 0s 247us/sample - loss: 0.1300 - accuracy: 0.9617\n",
      "Epoch 53/150\n",
      "235/235 [==============================] - 0s 268us/sample - loss: 0.1248 - accuracy: 0.9574\n",
      "Epoch 54/150\n",
      "235/235 [==============================] - 0s 264us/sample - loss: 0.1205 - accuracy: 0.9617\n",
      "Epoch 55/150\n",
      "235/235 [==============================] - 0s 238us/sample - loss: 0.1135 - accuracy: 0.9617\n",
      "Epoch 56/150\n",
      "235/235 [==============================] - 0s 238us/sample - loss: 0.1076 - accuracy: 0.9660\n",
      "Epoch 57/150\n",
      "235/235 [==============================] - 0s 230us/sample - loss: 0.1033 - accuracy: 0.9660\n",
      "Epoch 58/150\n",
      "235/235 [==============================] - 0s 272us/sample - loss: 0.0975 - accuracy: 0.9702\n",
      "Epoch 59/150\n",
      "235/235 [==============================] - 0s 251us/sample - loss: 0.0946 - accuracy: 0.9745\n",
      "Epoch 60/150\n",
      "235/235 [==============================] - 0s 243us/sample - loss: 0.0910 - accuracy: 0.9745\n",
      "Epoch 61/150\n",
      "235/235 [==============================] - 0s 251us/sample - loss: 0.0907 - accuracy: 0.9745\n",
      "Epoch 62/150\n",
      "235/235 [==============================] - 0s 277us/sample - loss: 0.0876 - accuracy: 0.9745\n",
      "Epoch 63/150\n",
      "235/235 [==============================] - 0s 243us/sample - loss: 0.0822 - accuracy: 0.9787\n",
      "Epoch 64/150\n",
      "235/235 [==============================] - 0s 247us/sample - loss: 0.0809 - accuracy: 0.9745\n",
      "Epoch 65/150\n",
      "235/235 [==============================] - 0s 277us/sample - loss: 0.0774 - accuracy: 0.9787\n",
      "Epoch 66/150\n",
      "235/235 [==============================] - 0s 268us/sample - loss: 0.0763 - accuracy: 0.9787\n",
      "Epoch 67/150\n",
      "235/235 [==============================] - 0s 234us/sample - loss: 0.0741 - accuracy: 0.9787\n",
      "Epoch 68/150\n",
      "235/235 [==============================] - 0s 238us/sample - loss: 0.0710 - accuracy: 0.9787\n",
      "Epoch 69/150\n",
      "235/235 [==============================] - 0s 238us/sample - loss: 0.0699 - accuracy: 0.9830\n",
      "Epoch 70/150\n",
      "235/235 [==============================] - 0s 243us/sample - loss: 0.0677 - accuracy: 0.9787\n",
      "Epoch 71/150\n",
      "235/235 [==============================] - 0s 238us/sample - loss: 0.0656 - accuracy: 0.9830\n",
      "Epoch 72/150\n",
      "235/235 [==============================] - 0s 290us/sample - loss: 0.0636 - accuracy: 0.9830\n",
      "Epoch 73/150\n",
      "235/235 [==============================] - 0s 260us/sample - loss: 0.0627 - accuracy: 0.9830\n",
      "Epoch 74/150\n",
      "235/235 [==============================] - 0s 247us/sample - loss: 0.0609 - accuracy: 0.9872\n",
      "Epoch 75/150\n",
      "235/235 [==============================] - 0s 234us/sample - loss: 0.0590 - accuracy: 0.9872\n",
      "Epoch 76/150\n",
      "235/235 [==============================] - 0s 294us/sample - loss: 0.0579 - accuracy: 0.9872\n",
      "Epoch 77/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235/235 [==============================] - 0s 251us/sample - loss: 0.0560 - accuracy: 0.9872\n",
      "Epoch 78/150\n",
      "235/235 [==============================] - 0s 268us/sample - loss: 0.0558 - accuracy: 0.9872\n",
      "Epoch 79/150\n",
      "235/235 [==============================] - 0s 247us/sample - loss: 0.0534 - accuracy: 0.9872\n",
      "Epoch 80/150\n",
      "235/235 [==============================] - 0s 234us/sample - loss: 0.0536 - accuracy: 0.9872\n",
      "Epoch 81/150\n",
      "235/235 [==============================] - 0s 221us/sample - loss: 0.0509 - accuracy: 0.9915\n",
      "Epoch 82/150\n",
      "235/235 [==============================] - 0s 234us/sample - loss: 0.0492 - accuracy: 0.9872\n",
      "Epoch 83/150\n",
      "235/235 [==============================] - 0s 260us/sample - loss: 0.0492 - accuracy: 0.9872\n",
      "Epoch 84/150\n",
      "235/235 [==============================] - 0s 268us/sample - loss: 0.0475 - accuracy: 0.9915\n",
      "Epoch 85/150\n",
      "235/235 [==============================] - 0s 272us/sample - loss: 0.0470 - accuracy: 0.9915\n",
      "Epoch 86/150\n",
      "235/235 [==============================] - 0s 238us/sample - loss: 0.0448 - accuracy: 0.9915\n",
      "Epoch 87/150\n",
      "235/235 [==============================] - 0s 260us/sample - loss: 0.0450 - accuracy: 0.9915\n",
      "Epoch 88/150\n",
      "235/235 [==============================] - 0s 230us/sample - loss: 0.0432 - accuracy: 0.9957\n",
      "Epoch 89/150\n",
      "235/235 [==============================] - 0s 264us/sample - loss: 0.0427 - accuracy: 0.9915\n",
      "Epoch 90/150\n",
      "235/235 [==============================] - 0s 238us/sample - loss: 0.0418 - accuracy: 0.9915\n",
      "Epoch 91/150\n",
      "235/235 [==============================] - 0s 255us/sample - loss: 0.0409 - accuracy: 0.9957\n",
      "Epoch 92/150\n",
      "235/235 [==============================] - 0s 255us/sample - loss: 0.0402 - accuracy: 0.9915\n",
      "Epoch 93/150\n",
      "235/235 [==============================] - 0s 259us/sample - loss: 0.0401 - accuracy: 0.9915\n",
      "Epoch 94/150\n",
      "235/235 [==============================] - 0s 285us/sample - loss: 0.0391 - accuracy: 0.9957\n",
      "Epoch 95/150\n",
      "235/235 [==============================] - 0s 285us/sample - loss: 0.0393 - accuracy: 0.9915\n",
      "Epoch 96/150\n",
      "235/235 [==============================] - 0s 264us/sample - loss: 0.0376 - accuracy: 0.9915\n",
      "Epoch 97/150\n",
      "235/235 [==============================] - 0s 251us/sample - loss: 0.0373 - accuracy: 0.9957\n",
      "Epoch 98/150\n",
      "235/235 [==============================] - 0s 251us/sample - loss: 0.0374 - accuracy: 0.9957\n",
      "Epoch 99/150\n",
      "235/235 [==============================] - 0s 264us/sample - loss: 0.0364 - accuracy: 0.9957\n",
      "Epoch 100/150\n",
      "235/235 [==============================] - 0s 268us/sample - loss: 0.0360 - accuracy: 0.9957\n",
      "Epoch 101/150\n",
      "235/235 [==============================] - 0s 234us/sample - loss: 0.0354 - accuracy: 0.9915\n",
      "Epoch 102/150\n",
      "235/235 [==============================] - 0s 268us/sample - loss: 0.0351 - accuracy: 0.9957\n",
      "Epoch 103/150\n",
      "235/235 [==============================] - 0s 264us/sample - loss: 0.0344 - accuracy: 0.9957\n",
      "Epoch 104/150\n",
      "235/235 [==============================] - 0s 255us/sample - loss: 0.0349 - accuracy: 0.9957\n",
      "Epoch 105/150\n",
      "235/235 [==============================] - 0s 226us/sample - loss: 0.0336 - accuracy: 0.9957\n",
      "Epoch 106/150\n",
      "235/235 [==============================] - 0s 247us/sample - loss: 0.0333 - accuracy: 0.9957\n",
      "Epoch 107/150\n",
      "235/235 [==============================] - 0s 242us/sample - loss: 0.0329 - accuracy: 0.9957\n",
      "Epoch 108/150\n",
      "235/235 [==============================] - 0s 238us/sample - loss: 0.0325 - accuracy: 0.9957\n",
      "Epoch 109/150\n",
      "235/235 [==============================] - 0s 285us/sample - loss: 0.0323 - accuracy: 0.9957\n",
      "Epoch 110/150\n",
      "235/235 [==============================] - 0s 255us/sample - loss: 0.0322 - accuracy: 0.9915\n",
      "Epoch 111/150\n",
      "235/235 [==============================] - 0s 264us/sample - loss: 0.0330 - accuracy: 0.9957\n",
      "Epoch 112/150\n",
      "235/235 [==============================] - 0s 247us/sample - loss: 0.0313 - accuracy: 0.9915\n",
      "Epoch 113/150\n",
      "235/235 [==============================] - 0s 260us/sample - loss: 0.0308 - accuracy: 0.9957\n",
      "Epoch 114/150\n",
      "235/235 [==============================] - 0s 268us/sample - loss: 0.0306 - accuracy: 0.9957\n",
      "Epoch 115/150\n",
      "235/235 [==============================] - 0s 247us/sample - loss: 0.0304 - accuracy: 0.9957\n",
      "Epoch 116/150\n",
      "235/235 [==============================] - 0s 260us/sample - loss: 0.0298 - accuracy: 0.9957\n",
      "Epoch 117/150\n",
      "235/235 [==============================] - 0s 272us/sample - loss: 0.0303 - accuracy: 0.9915\n",
      "Epoch 118/150\n",
      "235/235 [==============================] - 0s 264us/sample - loss: 0.0292 - accuracy: 0.9957\n",
      "Epoch 119/150\n",
      "235/235 [==============================] - 0s 243us/sample - loss: 0.0289 - accuracy: 0.9957\n",
      "Epoch 120/150\n",
      "235/235 [==============================] - 0s 238us/sample - loss: 0.0292 - accuracy: 0.9957\n",
      "Epoch 121/150\n",
      "235/235 [==============================] - 0s 260us/sample - loss: 0.0283 - accuracy: 0.9957\n",
      "Epoch 122/150\n",
      "235/235 [==============================] - 0s 234us/sample - loss: 0.0280 - accuracy: 0.9957\n",
      "Epoch 123/150\n",
      "235/235 [==============================] - 0s 226us/sample - loss: 0.0280 - accuracy: 0.9957\n",
      "Epoch 124/150\n",
      "235/235 [==============================] - 0s 251us/sample - loss: 0.0274 - accuracy: 0.9957\n",
      "Epoch 125/150\n",
      "235/235 [==============================] - 0s 247us/sample - loss: 0.0281 - accuracy: 0.9957\n",
      "Epoch 126/150\n",
      "235/235 [==============================] - 0s 264us/sample - loss: 0.0275 - accuracy: 0.9957\n",
      "Epoch 127/150\n",
      "235/235 [==============================] - 0s 277us/sample - loss: 0.0266 - accuracy: 0.9957\n",
      "Epoch 128/150\n",
      "235/235 [==============================] - 0s 272us/sample - loss: 0.0271 - accuracy: 0.9957\n",
      "Epoch 129/150\n",
      "235/235 [==============================] - 0s 285us/sample - loss: 0.0264 - accuracy: 0.9957\n",
      "Epoch 130/150\n",
      "235/235 [==============================] - 0s 255us/sample - loss: 0.0263 - accuracy: 0.9957\n",
      "Epoch 131/150\n",
      "235/235 [==============================] - 0s 264us/sample - loss: 0.0264 - accuracy: 0.9957\n",
      "Epoch 132/150\n",
      "235/235 [==============================] - 0s 243us/sample - loss: 0.0256 - accuracy: 0.9957\n",
      "Epoch 133/150\n",
      "235/235 [==============================] - 0s 264us/sample - loss: 0.0268 - accuracy: 0.9957\n",
      "Epoch 134/150\n",
      "235/235 [==============================] - 0s 260us/sample - loss: 0.0251 - accuracy: 0.9957\n",
      "Epoch 135/150\n",
      "235/235 [==============================] - 0s 315us/sample - loss: 0.0248 - accuracy: 0.9957\n",
      "Epoch 136/150\n",
      "235/235 [==============================] - 0s 230us/sample - loss: 0.0252 - accuracy: 0.9957\n",
      "Epoch 137/150\n",
      "235/235 [==============================] - 0s 234us/sample - loss: 0.0254 - accuracy: 0.9957\n",
      "Epoch 138/150\n",
      "235/235 [==============================] - 0s 221us/sample - loss: 0.0245 - accuracy: 0.9957\n",
      "Epoch 139/150\n",
      "235/235 [==============================] - 0s 226us/sample - loss: 0.0250 - accuracy: 0.9957\n",
      "Epoch 140/150\n",
      "235/235 [==============================] - 0s 255us/sample - loss: 0.0253 - accuracy: 0.9957\n",
      "Epoch 141/150\n",
      "235/235 [==============================] - 0s 238us/sample - loss: 0.0243 - accuracy: 0.9957\n",
      "Epoch 142/150\n",
      "235/235 [==============================] - 0s 268us/sample - loss: 0.0247 - accuracy: 0.9957\n",
      "Epoch 143/150\n",
      "235/235 [==============================] - 0s 247us/sample - loss: 0.0240 - accuracy: 0.9957\n",
      "Epoch 144/150\n",
      "235/235 [==============================] - 0s 221us/sample - loss: 0.0239 - accuracy: 0.9957\n",
      "Epoch 145/150\n",
      "235/235 [==============================] - 0s 277us/sample - loss: 0.0239 - accuracy: 0.9957\n",
      "Epoch 146/150\n",
      "235/235 [==============================] - 0s 272us/sample - loss: 0.0233 - accuracy: 0.9957\n",
      "Epoch 147/150\n",
      "235/235 [==============================] - 0s 268us/sample - loss: 0.0230 - accuracy: 0.9957\n",
      "Epoch 148/150\n",
      "235/235 [==============================] - 0s 273us/sample - loss: 0.0237 - accuracy: 0.9957 - loss: 0.0226 - accuracy: 0.99\n",
      "Epoch 149/150\n",
      "235/235 [==============================] - 0s 268us/sample - loss: 0.0248 - accuracy: 0.9957\n",
      "Epoch 150/150\n",
      "235/235 [==============================] - 0s 247us/sample - loss: 0.0234 - accuracy: 0.9957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b28336d908>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, y=y_train, batch_size=16, epochs=150, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 0s 914us/sample - loss: 0.3251 - accuracy: 0.9310\n"
     ]
    }
   ],
   "source": [
    "err = model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3629641656217904, 0.92241377]\n"
     ]
    }
   ],
   "source": [
    "print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = [1,0,0.99539,-0.05889,0.85243,0.02306,0.83398,-0.37708,1,0.03760,0.85243,-0.17755,0.59755,-0.44945,0.60536,-0.38223,0.84356,-0.38542,0.58212,-0.32192,0.56971,-0.29674,0.36946,-0.47357,0.56811,-0.51171,0.41078,-0.46168,0.21266,-0.34090,0.42267,-0.54487,0.18641,-0.45300]\n",
    "yhat = model.predict([row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9991672]], dtype=float32)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
